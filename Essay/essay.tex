\documentclass[12pt]{article}
\usepackage{fullpage,graphicx,psfrag,amsmath,amsfonts,verbatim}
\usepackage[small,bf]{caption}
\usepackage{amsthm}
% \usepackage[hidelinks]{hyperref}
\usepackage{hyperref}
\usepackage{bbm} % for the indicator function to look good
\usepackage{color}
\usepackage{mathtools}
\usepackage{fancyhdr} % for the header
\usepackage{booktabs} % for regression table display (toprule, midrule, bottomrule)
\usepackage{adjustbox} % for regression table display
\usepackage{threeparttable} % to use table notes
\usepackage{natbib} % for bibliography
\usepackage{tikz}
\usepackage{subcaption} % for subfigures

\input newcommand.tex
% \renewcommand{\thesubsection}{} 
\bibliographystyle{apalike}
% \setlength{\parindent}{0pt} % remove the automatic indentation

\title{\textbf{An Adversarial Approach to Structural Estimation}}
\author{TETSUYA KAJI, ELENA MANRESA, GUILLAUME POULIOT}
\date{Zixuan, Huixin}

\begin{document}
\maketitle
% \thispagestyle{empty}
% \begin{abstract}

% \end{abstract}

% \newpage
\thispagestyle{empty}
\tableofcontents
% \newpage

% \setcounter{page}{1}

\section{Adversarial Framework} \label{sec:framework}
In this section, we layout the basic framework of the adversarial approach.
Such adversarial (min-max zero-sum game) is not new, yet the
implementation/adaptation of it in generative tasks (e.g., image generation),
first proposed by \citet{goodfellow2014}, was shown to perform really well
under different settings. By training iteratively (back and forth) a
discriminator that tries to distinguish fake from true, and a generator that
reacts by producing harder-to-distinguish fake data, the algorithm can generate
new objects that closely resembles the existing ones. The mathematical form of
the game can be written as the following:
\begin{equation*}
    \min_G \max_D L(D, G)
    = \mathbb{E}_{x_r \sim p_{r}(x)} [\log D(x_r)] + \mathbb{E}_{x_g \sim p_g(x)} [\log(1 - D(x_g))]
\end{equation*}
Empirically, the loss function is
\begin{equation}\label{eq:empirical_loss}
    L(D, G)=\frac{1}{n} \sum_{i=1}^n \log D(x_i) + \frac{1}{m} \sum_{j=1}^m \log (1-D(x_j))
\end{equation}

Instead of directly explaining the objective function of the problem. I will
disentangle the problem from left to right. From this expression, we can see
that there are two things we want to optimize over, the discriminator $D$ and
the generator $G$.

The way that generator works is by taking some input noise $z\sim p_z(z)$ and
mapping it to the data space $x_g = G(z)$. Since we know the input noise
distribution $p_z(z)$ (usually normal or uniform), as well as the function
$G(\dot)$, we can compute the distribution of the generated data $p_g(x)$. Up
til this point, we have at our hands two sets of data points, one is fake whose
distribution $p_g$ we know of, the other real whose distribution $p_r$ we have
no clue of.

Given a set of points $\set{x_r}_i$ and $\set{x_g}_i$, how can we train a
classification model that can distinguish between the two? That is to say, take
the value of one data $x$, the classifier $D$ outputs a value between 0 and 1.
A \textit{good} classifier should output a value closer to 1 when the input is
real, and closer to 0 when the input is fake.

Recall that to train a \textit{good} \textbf{classifier}, the usual objective
function is the cross-entropy loss (equivalent to log-likelihood). The
following is a review of the cross entropy between two distribution $x~p$ and
$x~q$, defined as
\begin{equation*}
    H(p, q) = -\mathbb{E}_p[\log(q)]
\end{equation*}
In the context of binary classification, for a given point $x_i$ with label $y_i$, the cross entropy loss is
\begin{equation*}
    H(p, q) = - \pa{ p(x\in \text{Real}) \log q(x\in \text{Real}) + p(x\in \text{Fake})\log q(x\in \text{Fake})} = -(y_i \log D(x_i) + (1-y_i) \log (1-D(x_i)))
\end{equation*}
Summing over all points $n+m$, we have
\begin{equation*}
    -\frac{1}{m+n}\sum_i y_i \log D(x_i) + (1-y_i) \log (1-D(x_i))
\end{equation*}
This is the cross entropy loss of the classifier, which is equivalent to the log-likelihood function.
Notice that this is not exactly the same as the $L(D, G)$ defined above \ref{eq:empirical_loss} which puts different weights on the two true and fake points with weights $m:n$.

The reason why I am detailing the training out is that later we will be
comparing the objective function MLE, AdE and SMM. I was initially confused
about the difference between the MLE and AdE because the inner maximization
function of AdE looks almost the same as the log-likelihood objective of MLE.
Yet they are doing completely different things. While MLE is directly
maximizing the likelihood of observing the real data to find the true
parameters, the AdE's inner likelihood maximizing is only an intermediate step
to push the generator to find the true parameters. Details will be given
section \ref{sec:comparison}.

Having said that, let's take the given cross-entropy loss $L(G,D)$ and see how
its value changes as we choose different $D$ and $G$.

Notice that the empirical cross entropy loss is

Now I examine how the value of $L(D, G)$ changes as we update $D$ and $G$.
First, let us fix $G \equiv p_g$. We examine how the choice of $D$ affects the
value of $L(D, G)$. I summarize them into the following 4 cases.
\begin{itemize}
    \item Perfect $D$: $D(x_i)$ assigns value 1 to all $x_i \in p_r$ and 0 to all $x_i
              \in p_g$. In this case, $D(x)$ is not a valid function because for two points
          $x_1=x_2$ where $x_1 \in p_r$ and $x_2 \in p_g$, the discriminator
          \textit{predicts} $D(x_1)=1$ and $D(x_2)=0$. However, this perfect classifier
          gives the upper bound of the loss as 0.
    \item Ignorant $D$: $D(x_i)$ assigns value $\frac{1}{2}$ to all $x_i$. In this case,
          this is lower bound which is $\log \frac{1}{2} + \log \frac{1}{2} = -2\log 2$.
    \item Oracle $D$: $D(x_i)=\frac{p_r(x_i)}{p_r(x_i)+p_g(x_i)}$. This is the optimal
          discriminator derived by taking derivative of $L(D, G)$ with respect to $D$, or
          we can simply view it as posterior probability of $x_i$ being real with equal
          prior $1/2$. If the discriminator knows the distribution $p_r(x;\theta_0)$ and
          $p_g(x;\theta)$, this is the optimal discriminator.
    \item Correctly specified $D$: $D(x_i;\lambda)$ is a correctly specified
          discriminator if there exists a $\lambda^*$ such that
          $D(x_i;\lambda^*)=\frac{p_r(x_i;\theta_0)}{p_r(x_i;\theta_0)+p_g(x_i;\theta)}$.
          In this case, the convergence of $D(x_i;\lambda)$ to the oracle
          $D(x_i:\lambda^*)$ is guaranteed.
    \item Flexible $D$: In reality, neither the oracle nor the correctly specified $D$ is
          available. It is often the case that we take a flexible parametric form of $D$,
          for example $D(x)=\Lambda(\lambda_0+\lambda_1 x+\lambda_2 x^2+\cdots)$. Or we
          can go to the flexibility extreme and train a neural network classifier to
          approximate the oracle $D$. The convergence of $D_\text{NN}$ to the oracle $D$
          is proved in \citet{}.
\end{itemize}

Let us fix the discriminator $D$ and examine how the choice of $G$ affects the
value of $L(D, G)$. Notice that the optimal discriminator is
$D(x_i)=\frac{p_r(x_i)}{p_r(x_i)+p_g(x_i)}$. The optimal generator in this case
is $G(z)\sim p_r(x)$ rendering the oracle $D$ same as the ignorant $D$
\footnote{$G$ is saying to $D$: I heard that you have learned something, no
    longer an ignorant young kid, but an oracle? Let me fool you again.}. If the
discriminator and the generator are both at its best, the loss function is
$-2\log 2$.

For the part of training $G$, if the true distribution $p_r$ is parametric,
e.g., a logistic distribution parametrized by location and scale. The training
of $G$ boils down to estimating the true $\theta_0$ that characterizes the true
distribution $p_r$. If our structural model comes with some parameters $\theta$
wiht the true $\theta_0$ corresponding to the one that produces the observed
data. The generator is trained as an estimator for $\theta_0$. In the following
section, we denote the adversarial generator estimator as AdE. One may have
noticed that if our focus is the generator, the discriminator can be regarded
as a nuisance intermediate step. Though we call it nuisance, it is crucial in
determining the performance of the AdE, including both the convergence rate and
the asymptotic distribution and efficiency. This will be further discussed in
section \ref{sec:performance}.

Note that in the estimation of structure parameters, $G$ is parametric. While
in the original GAN, $G$ is trained using Neural network as well. This is
purely as a result of the different task at hands. If our goal is to generate
data that mimics the true data, neural network is certainly a better choice
than restrictive parametric assumption. However, if our goal is to estimate the
distribution of the true data (rather than generating something new), the
parametric assumption gives us the value that we can interpret in an economic
sense.

The next section~\ref{sec:related_applications} will discuss the two
applications of GAN in Economics and Finance with similar objective of
generating new data.

\section{Related Applications} \label{sec:related_applications}

The first paper that applies the WGAN in Economcics is \citet{}. Instead of
generating images that can fool the human's eyes, the authors wants to generate
new samples that looks like the data collected from a costly experiment. For
example, xxx's experiment provides researchers with one real sample of n
individuals. The researcher can apply different estiamtors to estimate the
average treatment effect. However, when it comes to evaluate the performance of
estimators, ususally it would require monte carlo simulation of many samples.
More often than not, the credibility of the practice is called into question
due to the specific design of the simulation. One estimator may perform better
only as a result of that particular simulation setup. The author then proposes
WGAN

\section{Performance} \label{sec:performance}

\section{Computation} \label{sec:computation}
\pagebreak
\newpage
\bibliography{../References/ref.bib}

\end{document}